{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e62f530-4e55-4421-b79f-ae0a4e1d5431",
   "metadata": {},
   "source": [
    "# https://nlp100.github.io/ja/ch04.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88df4d-3cbd-4726-9108-36baccce468a",
   "metadata": {},
   "source": [
    "## 第5章: 係り受け解析  \n",
    "日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4192c-3bf3-46e9-be8b-8c5e796a5483",
   "metadata": {},
   "source": [
    "ステップ1: 依存関係のインストール  \n",
    "sudo apt update  \n",
    "sudo apt install -y build-essential curl file git  \n",
    "sudo apt install -y mecab libmecab-dev mecab-ipadic-utf8  \n",
    "sudo apt install -y zlib1g-dev libcurl4-openssl-dev libxml2-dev  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7485f77-2c8e-4562-a747-446735d2ce80",
   "metadata": {},
   "source": [
    "ステップ2: CRF++のインストール  \n",
    "git clone https://github.com/taku910/crfpp.git  \n",
    "cd crfpp  \n",
    "./configure  \n",
    "make  \n",
    "sudo make install  \n",
    "cd ..  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb48f19-311f-442a-b088-e34e5833790e",
   "metadata": {},
   "source": [
    "ステップ3: CaboChaのダウンロードとビルド  \n",
    "git clone https://github.com/taku910/cabocha.git  \n",
    "cd cabocha  \n",
    "sudo apt-get install autoconf automake libtool  \n",
    "autoreconf -i  \n",
    "./configure --with-mecab-config=`which mecab-config` --with-charset=utf8  \n",
    "make  \n",
    "sudo make install  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4848d-3ceb-4fec-a7e6-f9de6aa1f709",
   "metadata": {},
   "source": [
    "swig_import_helper`について、以下の部分を修正\n",
    "```\n",
    "def swig_import_helper():\n",
    "    import os  \n",
    "    import importlib.util  \n",
    "    spec = importlib.util.find_spec('_CaboCha', [os.path.dirname(__file__)])  \n",
    "    if spec is None:  \n",
    "        raise ImportError('_CaboCha module not found')  \n",
    "    _mod = importlib.util.module_from_spec(spec)  \n",
    "    spec.loader.exec_module(_mod)  \n",
    "    return _mod  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105fa60d-0b1c-48e6-857a-165bb8f35941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iconv_open is not supported\n"
     ]
    }
   ],
   "source": [
    "import CaboCha\n",
    "CBC = CaboCha.Parser()\n",
    "divtext = []\n",
    "with open(\"./datafiles/ai.ja.txt\", \"r\") as f, open(\"./datafiles/ai.ja.txt.parsed\", \"w\") as f2:\n",
    "    lines = f.readlines()\n",
    "    for text in lines:\n",
    "        if \"。\" in text:\n",
    "            temp = text.split(\"。\")\n",
    "            temp = [x + \"。\" for x in temp if x != '']\n",
    "            divtext.extend(temp)\n",
    "    for text in divtext:\n",
    "        tree = CBC.parse(text)\n",
    "        f2.write(tree.toString(CaboCha.FORMAT_LATTICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "532eac8c-92cb-4886-8290-905939f89597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能\n",
      "\n",
      "人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という概念と『コンピュータ（）』という道具を用いて『知能』を研究する計算機科学（）の一分野」を指す語。「言語の理解や推論、問題解決などの知的行動を人間に代わってコンピューターに行わせる技術」、または、「計算機（コンピュータ）による知的な情報処理システムの設計や実現に関する研究分野」ともされる。\n",
      "\n",
      "『日本大百科全書(ニッポニカ)』の解説で、情報工学者・通信工学者の佐藤理史は次のように述べている。\n"
     ]
    }
   ],
   "source": [
    "!head -5 ./datafiles/ai.ja.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e9d72b-21d4-4843-8584-52331aa608d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 0 14D 1/1 -1.776924\n",
      "人工\t名詞,一般,*,*,*,*,人工,ジンコウ,ジンコー\n",
      "知能\t名詞,一般,*,*,*,*,知能,チノウ,チノー\n",
      "* 1 14D 2/3 -1.776924\n",
      "（\t記号,括弧開,*,*,*,*,（,（,（\n",
      "じん\t名詞,一般,*,*,*,*,じん,ジン,ジン\n",
      "こうち\t名詞,一般,*,*,*,*,こうち,コウチ,コーチ\n",
      "のう\t助詞,終助詞,*,*,*,*,のう,ノウ,ノー\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "* 2 3D 0/0 0.592011\n",
      "AI\t名詞,一般,*,*,*,*,*\n",
      "* 3 14D 1/5 -1.776924\n",
      "〈\t記号,括弧開,*,*,*,*,〈,〈,〈\n",
      "エーアイ\t名詞,固有名詞,一般,*,*,*,*\n",
      "〉\t記号,括弧閉,*,*,*,*,〉,〉,〉\n",
      "）\t記号,括弧閉,*,*,*,*,）,）,）\n",
      "と\t助詞,格助詞,引用,*,*,*,と,ト,ト\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n"
     ]
    }
   ],
   "source": [
    "!head -20 ./datafiles/ai.ja.txt.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03025a1-eac5-47b2-952e-d2ddf2c7f15c",
   "metadata": {},
   "source": [
    "## 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "095078d3-41c4-4816-bcfd-0d89dd82e90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "冒頭の文の形態素列:\n",
      "Morph(surface='人工', base='人工', pos='名詞', pos1='一般')\n",
      "Morph(surface='知能', base='知能', pos='名詞', pos1='一般')\n",
      "Morph(surface='（', base='（', pos='記号', pos1='括弧開')\n",
      "Morph(surface='じん', base='じん', pos='名詞', pos1='一般')\n",
      "Morph(surface='こうち', base='こうち', pos='名詞', pos1='一般')\n",
      "Morph(surface='のう', base='のう', pos='助詞', pos1='終助詞')\n",
      "Morph(surface='、', base='、', pos='記号', pos1='読点')\n",
      "Morph(surface='、', base='、', pos='記号', pos1='読点')\n",
      "Morph(surface='AI', base='*', pos='名詞', pos1='一般')\n",
      "Morph(surface='〈', base='〈', pos='記号', pos1='括弧開')\n",
      "Morph(surface='エーアイ', base='*', pos='名詞', pos1='固有名詞')\n",
      "Morph(surface='〉', base='〉', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='）', base='）', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='と', base='と', pos='助詞', pos1='格助詞')\n",
      "Morph(surface='は', base='は', pos='助詞', pos1='係助詞')\n",
      "Morph(surface='、', base='、', pos='記号', pos1='読点')\n",
      "Morph(surface='「', base='「', pos='記号', pos1='括弧開')\n",
      "Morph(surface='『', base='『', pos='記号', pos1='括弧開')\n",
      "Morph(surface='計算', base='計算', pos='名詞', pos1='サ変接続')\n",
      "Morph(surface='（', base='（', pos='記号', pos1='括弧開')\n",
      "Morph(surface='）', base='）', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='』', base='』', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='という', base='という', pos='助詞', pos1='格助詞')\n",
      "Morph(surface='概念', base='概念', pos='名詞', pos1='一般')\n",
      "Morph(surface='と', base='と', pos='助詞', pos1='並立助詞')\n",
      "Morph(surface='『', base='『', pos='記号', pos1='括弧開')\n",
      "Morph(surface='コンピュータ', base='コンピュータ', pos='名詞', pos1='一般')\n",
      "Morph(surface='（', base='（', pos='記号', pos1='括弧開')\n",
      "Morph(surface='）', base='）', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='』', base='』', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='という', base='という', pos='助詞', pos1='格助詞')\n",
      "Morph(surface='道具', base='道具', pos='名詞', pos1='一般')\n",
      "Morph(surface='を', base='を', pos='助詞', pos1='格助詞')\n",
      "Morph(surface='用い', base='用いる', pos='動詞', pos1='自立')\n",
      "Morph(surface='て', base='て', pos='助詞', pos1='接続助詞')\n",
      "Morph(surface='『', base='『', pos='記号', pos1='括弧開')\n",
      "Morph(surface='知能', base='知能', pos='名詞', pos1='一般')\n",
      "Morph(surface='』', base='』', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='を', base='を', pos='助詞', pos1='格助詞')\n",
      "Morph(surface='研究', base='研究', pos='名詞', pos1='サ変接続')\n",
      "Morph(surface='する', base='する', pos='動詞', pos1='自立')\n",
      "Morph(surface='計算', base='計算', pos='名詞', pos1='サ変接続')\n",
      "Morph(surface='機', base='機', pos='名詞', pos1='接尾')\n",
      "Morph(surface='科学', base='科学', pos='名詞', pos1='一般')\n",
      "Morph(surface='（', base='（', pos='記号', pos1='括弧開')\n",
      "Morph(surface='）', base='）', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='の', base='の', pos='助詞', pos1='連体化')\n",
      "Morph(surface='一', base='一', pos='名詞', pos1='数')\n",
      "Morph(surface='分野', base='分野', pos='名詞', pos1='一般')\n",
      "Morph(surface='」', base='」', pos='記号', pos1='括弧閉')\n",
      "Morph(surface='を', base='を', pos='助詞', pos1='格助詞')\n",
      "Morph(surface='指す', base='指す', pos='動詞', pos1='自立')\n",
      "Morph(surface='語', base='語', pos='名詞', pos1='一般')\n",
      "Morph(surface='。', base='。', pos='記号', pos1='句点')\n"
     ]
    }
   ],
   "source": [
    "class Morph:\n",
    "    def __init__(self, pos):\n",
    "        \"\"\"\n",
    "        形態素を初期化します。\n",
    "        :param pos: 形態素情報が格納されたリスト\n",
    "        \"\"\"\n",
    "        self.surface = pos[0]  # 表層形\n",
    "        self.base = pos[7]     # 基本形\n",
    "        self.pos = pos[1]      # 品詞\n",
    "        self.pos1 = pos[2]     # 品詞細分類1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Morph(surface='{self.surface}', base='{self.base}', pos='{self.pos}', pos1='{self.pos1}')\"\n",
    "\n",
    "    @classmethod # Morphクラスから直接メソッドを呼び出すために指定\n",
    "    def parse_from_file(cls, file_path):\n",
    "        \"\"\"\n",
    "        形態素解析結果を読み込み、文ごとの Morph オブジェクトのリストを生成します。\n",
    "        :param file_path: ファイルのパス\n",
    "        :return: 文ごとの Morph オブジェクトのリスト\n",
    "        \"\"\"\n",
    "        morph_list = []\n",
    "        sentence = []\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()  # 空白や改行を除去\n",
    "                if line == \"EOS\":  # 文の区切り\n",
    "                    if sentence:\n",
    "                        morph_list.append(sentence)\n",
    "                        sentence = []\n",
    "                elif not line.startswith(\"*\"):  # 係り受け情報をスキップ\n",
    "                    cols = line.split(\"\\t\")\n",
    "                    if len(cols) > 1:\n",
    "                        features = cols[1].split(\",\")\n",
    "                        pos = [cols[0]] + features\n",
    "                        sentence.append(cls(pos))  # クラスメソッドを使ってインスタンスを生成\n",
    "\n",
    "        return morph_list\n",
    "\n",
    "\n",
    "# ファイルパスを指定して実行\n",
    "file_path = \"./datafiles/ai.ja.txt.parsed\"\n",
    "morph_list = Morph.parse_from_file(file_path)\n",
    "\n",
    "# 冒頭の文の形態素列を表示\n",
    "if morph_list:\n",
    "    print(\"冒頭の文の形態素列:\")\n",
    "    for morph in morph_list[0]:\n",
    "        print(morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647f23d-ec9d-4720-ab70-e08e32541d66",
   "metadata": {},
   "source": [
    "## 41. 係り受け解析結果の読み込み（文節・係り受け）  \n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb3a09b2-0830-4dc0-a80c-a46daafca1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "冒頭の文の文節と係り先:\n",
      "文節 0: 人工知能 -> なし\n",
      "文節 1: じんこうちのう -> なし\n",
      "文節 2: AI -> エーアイとは\n",
      "文節 3: エーアイとは -> なし\n",
      "文節 4: 計算という -> コンピュータという\n",
      "文節 5: 概念と -> コンピュータという\n",
      "文節 6: コンピュータという -> 道具を\n",
      "文節 7: 道具を -> 用いて\n",
      "文節 8: 用いて -> 研究する\n",
      "文節 9: 知能を -> 研究する\n",
      "文節 10: 研究する -> 計算機科学の\n",
      "文節 11: 計算機科学の -> 一分野を\n",
      "文節 12: 一分野を -> 指す\n",
      "文節 13: 指す -> なし\n"
     ]
    }
   ],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, morphs, dst):\n",
    "        \"\"\"\n",
    "        文節を表すクラス\n",
    "        :param morphs: Morphオブジェクトのリスト\n",
    "        :param dst: 係り先文節インデックス番号\n",
    "        \"\"\"\n",
    "        self.morphs = morphs  # 形態素（Morphオブジェクト）のリスト\n",
    "        self.dst = dst        # 係り先文節インデックス番号\n",
    "        self.srcs = []        # 係り元文節インデックス番号のリスト\n",
    "\n",
    "    def __repr__(self):\n",
    "        morph_text = ''.join([morph.surface for morph in self.morphs if morph.pos != \"記号\"])\n",
    "        return f\"Chunk(text='{morph_text}', dst={self.dst}, srcs={self.srcs})\"\n",
    "\n",
    "\n",
    "def parse_chunks(file_path):\n",
    "    \"\"\"\n",
    "    係り受け解析結果を読み込み、文ごとの Chunk オブジェクトのリストを生成する。\n",
    "    :param file_path: ファイルのパス\n",
    "    :return: 文ごとの Chunk オブジェクトのリスト\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    chunks = []\n",
    "    morphs = []\n",
    "    dst = -1\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"EOS\":\n",
    "                if chunks:\n",
    "                    for i, chunk in enumerate(chunks):\n",
    "                        # dstが有効な範囲内であることを確認\n",
    "                        if 0 <= chunk.dst < len(chunks):\n",
    "                            chunks[chunk.dst].srcs.append(i)\n",
    "                    sentences.append(chunks)\n",
    "                chunks = []\n",
    "            elif line.startswith(\"*\"):\n",
    "                if morphs:\n",
    "                    chunks.append(Chunk(morphs, dst))\n",
    "                    morphs = []\n",
    "                _, idx, dst, *_ = line.split()\n",
    "                dst = int(dst.rstrip(\"D\"))\n",
    "            else:\n",
    "                cols = line.split(\"\\t\")\n",
    "                if len(cols) > 1:\n",
    "                    features = cols[1].split(\",\")\n",
    "                    pos = [cols[0]] + features\n",
    "                    morphs.append(Morph(pos))\n",
    "        if morphs:\n",
    "            chunks.append(Chunk(morphs, dst))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# ファイルパスを指定して実行\n",
    "file_path = \"./datafiles/ai.ja.txt.parsed\"\n",
    "chunk_list = parse_chunks(file_path)\n",
    "\n",
    "# 冒頭の文の文節と係り先を表示\n",
    "if chunk_list:\n",
    "    print(\"冒頭の文の文節と係り先:\")\n",
    "    for i, chunk in enumerate(chunk_list[0]):\n",
    "        # 文節の文字列を取得\n",
    "        chunk_text = ''.join([m.surface for m in chunk.morphs if m.pos != \"記号\"])\n",
    "        \n",
    "        # 係り先の文字列を取得（範囲チェック付き）\n",
    "        if 0 <= chunk.dst < len(chunk_list[0]):\n",
    "            dst_text = ''.join([m.surface for m in chunk_list[0][chunk.dst].morphs if m.pos != \"記号\"])\n",
    "        else:\n",
    "            dst_text = \"なし\"\n",
    "        \n",
    "        print(f\"文節 {i}: {chunk_text} -> {dst_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c717966-ccb6-47fd-8146-468fc5ecbad8",
   "metadata": {},
   "source": [
    "## 42. 係り元と係り先の文節の表示  \n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cac7c824-6198-452c-a140-a1960d5baeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "冒頭3文の文節と係り先:\n",
      "\n",
      "【文 1】\n",
      "文節 0: 人工知能\tなし\n",
      "文節 1: じんこうちのう\tなし\n",
      "文節 2: AI\tエーアイとは\n",
      "文節 3: エーアイとは\tなし\n",
      "文節 4: 計算という\tコンピュータという\n",
      "文節 5: 概念と\tコンピュータという\n",
      "文節 6: コンピュータという\t道具を\n",
      "文節 7: 道具を\t用いて\n",
      "文節 8: 用いて\t研究する\n",
      "文節 9: 知能を\t研究する\n",
      "文節 10: 研究する\t計算機科学の\n",
      "文節 11: 計算機科学の\t一分野を\n",
      "文節 12: 一分野を\t指す\n",
      "文節 13: 指す\tなし\n",
      "\n",
      "【文 2】\n",
      "文節 0: 語\tなし\n",
      "文節 1: 言語の\t理解や\n",
      "文節 2: 理解や\t理解や\n",
      "文節 3: 推論\t推論\n",
      "文節 4: 問題解決などの\t問題解決などの\n",
      "文節 5: 知的行動を\t人間に\n",
      "文節 6: 人間に\t人間に\n",
      "文節 7: 代わって\tコンピューターに\n",
      "文節 8: コンピューターに\tコンピューターに\n",
      "文節 9: 行わせる\t行わせる\n",
      "文節 10: 技術または\t実現に関する\n",
      "文節 11: 計算機コンピュータによる\t知的な\n",
      "文節 12: 知的な\t知的な\n",
      "文節 13: 情報処理システムの\t設計や\n",
      "文節 14: 設計や\t設計や\n",
      "文節 15: 実現に関する\t実現に関する\n",
      "文節 16: 研究分野とも\t研究分野とも\n",
      "\n",
      "【文 3】\n",
      "文節 0: される\tなし\n"
     ]
    }
   ],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, morphs, dst):\n",
    "        \"\"\"\n",
    "        文節を表すクラス\n",
    "        :param morphs: Morphオブジェクトのリスト\n",
    "        :param dst: 係り先文節インデックス番号\n",
    "        \"\"\"\n",
    "        self.morphs = morphs  # 形態素（Morphオブジェクト）のリスト\n",
    "        self.dst = dst        # 係り先文節インデックス番号\n",
    "        self.srcs = []        # 係り元文節インデックス番号のリスト\n",
    "\n",
    "    def __repr__(self):\n",
    "        morph_text = ''.join([morph.surface for morph in self.morphs if morph.pos != \"記号\"])\n",
    "        return f\"Chunk(text='{morph_text}', dst={self.dst}, srcs={self.srcs})\"\n",
    "\n",
    "\n",
    "def parse_chunks(file_path):\n",
    "    \"\"\"\n",
    "    係り受け解析結果を読み込み、文ごとの Chunk オブジェクトのリストを生成する。\n",
    "    :param file_path: ファイルのパス\n",
    "    :return: 文ごとの Chunk オブジェクトのリスト\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    chunks = []\n",
    "    morphs = []\n",
    "    dst = -1\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"EOS\":\n",
    "                if chunks:\n",
    "                    for i, chunk in enumerate(chunks):\n",
    "                        # dstが有効な範囲内であることを確認\n",
    "                        if 0 <= chunk.dst < len(chunks):\n",
    "                            chunks[chunk.dst].srcs.append(i)\n",
    "                    sentences.append(chunks)\n",
    "                chunks = []\n",
    "            elif line.startswith(\"*\"):\n",
    "                if morphs:\n",
    "                    chunks.append(Chunk(morphs, dst))\n",
    "                    morphs = []\n",
    "                _, idx, dst, *_ = line.split()\n",
    "                dst = int(dst.rstrip(\"D\"))\n",
    "            else:\n",
    "                cols = line.split(\"\\t\")\n",
    "                if len(cols) > 1:\n",
    "                    features = cols[1].split(\",\")\n",
    "                    pos = [cols[0]] + features\n",
    "                    morphs.append(Morph(pos))\n",
    "        if morphs:\n",
    "            chunks.append(Chunk(morphs, dst))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# ファイルパスを指定して実行\n",
    "file_path = \"./datafiles/ai.ja.txt.parsed\"\n",
    "chunk_list = parse_chunks(file_path)\n",
    "\n",
    "# 冒頭の文の文節と係り先を表示\n",
    "if chunk_list:\n",
    "    print(\"冒頭3文の文節と係り先:\")\n",
    "    for sentence_idx, sentence in enumerate(chunk_list[:3]):  # 冒頭3文\n",
    "        print(f\"\\n【文 {sentence_idx + 1}】\")\n",
    "        for i, chunk in enumerate(sentence):\n",
    "            # 文節の文字列を取得\n",
    "            chunk_text = ''.join([m.surface for m in chunk.morphs if m.pos != \"記号\"])\n",
    "            \n",
    "            # 係り先の文字列を取得（範囲チェック付き）\n",
    "            if 0 <= chunk.dst < len(sentence):\n",
    "                dst_text = ''.join([m.surface for m in sentence[chunk.dst].morphs if m.pos != \"記号\"])\n",
    "            else:\n",
    "                dst_text = \"なし\"\n",
    "            \n",
    "            print(f\"文節 {i}: {chunk_text}\\t{dst_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ca30b-6b79-42f2-af55-bde641a46cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
